{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OhJunYoung21/artificial-inteliigence/blob/main/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVMZSR_bohK6"
      },
      "source": [
        "# Machine Learning - Lab Session 2\n",
        "\n",
        "This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. \n",
        "\n",
        "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
        "\n",
        "### Submitting your work:\n",
        "- <font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.\n",
        "- Commit the `.ipynb` file on your github repository and submit URL on E-Ruri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbPO7auSohLA"
      },
      "source": [
        "## Load `diabetes` dataset for Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "KKMg-XaUohLB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "X, y = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "# Use only one feature\n",
        "X = X[:, np.newaxis, 2]\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "X_train = X[:-20]\n",
        "X_test = X[-20:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "y_train = y[:-20]\n",
        "y_test = y[-20:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data size\n",
        "print('X: ' + str(X.shape))\n",
        "print('y: ' + str(y.shape))\n",
        "\n",
        "print('X_train: ' + str(X_train.shape))\n",
        "print('y_train: ' + str(y_train.shape))\n",
        "\n",
        "print('X_test: ' + str(X_test.shape))\n",
        "print('y_test: ' + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErNryUFKqfT2",
        "outputId": "cbe799ba-d222-4aa2-c375-6327059aebee"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (442, 1)\n",
            "y: (442,)\n",
            "X_train: (422, 1)\n",
            "y_train: (422,)\n",
            "X_test: (20, 1)\n",
            "y_test: (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb3fmRd2ohLD"
      },
      "source": [
        "### <font color=blue>[Lab #2-1]</font>  Linear regression with sklearn (20 points)\n",
        "\n",
        "Use **linear_model** from Scikit-Learn [[reference](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8cxUo75ohLD",
        "outputId": "a8a428b4-0d49-47b8-a5bf-597975cce71f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SK Parameters: 152.9189, 938.2379\n",
            "SK train MSE: 3955.0199\n",
            "SK test MSE: 2548.0724\n"
          ]
        }
      ],
      "source": [
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# create model  \n",
        "sk_lin_regr = linear_model.LinearRegression()\n",
        "\n",
        "# train model\n",
        "sk_lin_regr.fit(X_train, y_train)\n",
        "print('SK Parameters: %.4f, %.4f' %\n",
        "      (sk_lin_regr.intercept_, np.squeeze(sk_lin_regr.coef_, axis=0)))\n",
        "\n",
        "# inferece with train data\n",
        "y_train_pred = sk_lin_regr.predict(X_train)\n",
        "print('SK train MSE: %.4f' %\n",
        "      mean_squared_error(y_train, y_train_pred) )\n",
        "\n",
        "# inferece with test data\n",
        "y_test_pred = sk_lin_regr.predict(X_test)\n",
        "print('SK test MSE: %.4f' %\n",
        "      mean_squared_error(y_test, y_test_pred) )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot outputs\n",
        "plt.scatter(X_test, y_test, color='black')\n",
        "plt.plot(X_test, y_test_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "pVCczHKNsJFl",
        "outputId": "e2bb9882-8864-418c-b5b3-ba93ae48c111"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2PInhrLohLE"
      },
      "source": [
        "### <font color=blue>[Lab #2-2]</font> Linear regression without sklearn (20 points)\n",
        "1. Complete the following class definition.  \n",
        "2. You can write your code only within the marked with comments.\n",
        "\n",
        "**[hint]** You can use `numpy.linalg.inv` for inverse and `np.matmul` for matrix multiplication.\n",
        "$$\n",
        "\\mathbf{X}^\\dagger = (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\n",
        "\\\\\n",
        "\\mathbf{w}_{\\textrm{lin}}=\\mathbf{X}^\\dagger y\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "hJxgV0hmohLF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy.linalg as lin\n",
        "\n",
        "inv = lin.inv\n",
        "\n",
        "class LinearRegression():\n",
        "    def fit(self, X, y):\n",
        "        #linear regression\n",
        "        self.X_psuedo_inv = np.matmul(inv(np.matmul(X.T,X)),X.T)\n",
        "        self.w = np.matmul(X.T,y)  #내적을 구해야 되지 않나?\n",
        "\n",
        "    def predict(self, X):\n",
        "        return  X @ self.w\n",
        "    \n",
        "    def get_weights(self):\n",
        "        return self.w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60qrz1hPohLG"
      },
      "source": [
        "Extend $\\mathbf{X}$ with $\\mathbf{1}_d=(1,1,…,1)∈\\mathbb{R}^d$ using `add_one_column` method which we used in Lab 1.\n",
        "$$\n",
        "\\mathbf{X} = \\begin{bmatrix} x_1 \\\\\n",
        "x_2 \\\\\n",
        "\\vdots  \\\\\n",
        "x_d \\\\\n",
        "\\end{bmatrix}\n",
        "\\Rightarrow\n",
        "\\mathbf{X} = \\begin{bmatrix}\n",
        "1 & x_1 \\\\\n",
        "1 & x_2 \\\\\n",
        "\\vdots  & \\vdots  \\\\\n",
        "1 & x_d \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "By using X, you should compute optimal weight, `w_lin`.\n",
        "\n",
        "**[hint]** compute pseudo-inverse of $\\mathbf{X}$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_one_column(data):\n",
        "    # number of data records\n",
        "    N = len(data) \n",
        "\n",
        "    # add column of ones for x_0\n",
        "    return np.c_[np.ones(N), data] "
      ],
      "metadata": {
        "id": "CgZcg-uqvrDk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxJOCbLyohLG",
        "outputId": "8b6bd536-e17c-4ee0-99b1-859a2d06a02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_extneded:  (422, 2)\n",
            "X_test_extneded:  (20, 2)\n"
          ]
        }
      ],
      "source": [
        "X_train_extended = add_one_column(X_train)\n",
        "X_test_extended = add_one_column(X_test)\n",
        "print('X_train_extneded: ', str(X_train_extended.shape))\n",
        "print('X_test_extneded: ', str(X_test_extended.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "np_lin_regr = LinearRegression()\n",
        "\n",
        "# train model\n",
        "np_lin_regr.fit(X_train_extended, y_train)\n",
        "\n",
        "print('Numpy Parameters: %.4f, %.4f' %\n",
        "      (np_lin_regr.get_weights()[0], np_lin_regr.get_weights()[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pk4DGrCzcPK",
        "outputId": "3350a777-ae7d-4a2c-a3a6-f58bd476e860"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy Parameters: 64719.0000, 927.2647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inferece with train data\n",
        "y_train_pred = np_lin_regr.predict(X_train_extended)\n",
        "print('SK train MSE: %.4f' %\n",
        "      mean_squared_error(y_train, y_train_pred) )\n",
        "\n",
        "# inferece with test data\n",
        "y_test_pred = np_lin_regr.predict(X_test_extended)\n",
        "print('SK test MSE: %.4f' %\n",
        "      mean_squared_error(y_test, y_test_pred) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRs3NU6mzeWj",
        "outputId": "ccd9d754-1774-4329-e769-08facca6c24d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SK train MSE: 4168782118.7301\n",
            "SK test MSE: 4171036860.4568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot outputs\n",
        "plt.scatter(X_test, y_test, color='black')\n",
        "plt.plot(X_test, y_test_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "pl9GvuSHziIa",
        "outputId": "5e58628f-28c0-4f53-938d-012455c79028"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load `breast_cancer` data for Logistic Regression"
      ],
      "metadata": {
        "id": "iIIDaTRoDzXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "\n",
        "X = data.data[:, [0, 6]]\n",
        "y = data.target\n",
        "\n",
        "# show data size\n",
        "print('X: ' + str(X.shape))\n",
        "print('y: ' + str(y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4_Aksny2s6j",
        "outputId": "080185c9-8f0c-425e-c99e-9257e84909db"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (569, 2)\n",
            "y: (569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into train and test set."
      ],
      "metadata": {
        "id": "oiKAGoHkE43J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Show data size\n",
        "print('X_train: ' + str(X_train.shape))\n",
        "print('y_train: ' + str(y_train.shape))\n",
        "\n",
        "print('X_test: ' + str(X_test.shape))\n",
        "print('y_test: ' + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnqtj6zV2yX6",
        "outputId": "ec9125cc-db46-4bad-cde0-9e30d2bedf5b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (381, 2)\n",
            "y_train: (381,)\n",
            "X_test: (188, 2)\n",
            "y_test: (188,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>[Lab #2-3]</font> Logisitic regression with sklearn (20 points)\n",
        "Use **linear_model** from Scikit-Learn."
      ],
      "metadata": {
        "id": "K3r5414b1oXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "sk_logis_regr = LogisticRegression()\n",
        "\n",
        "# train model\n",
        "sk_logis_regr.fit(X_train, y_train)\n",
        "\n",
        "print('SK Parameters: %.4f, %.4f, %.4f' %\n",
        "      (sk_logis_regr.intercept_,\n",
        "       sk_logis_regr.coef_[0, 0], sk_logis_regr.coef_[0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV97BjCP3Zem",
        "outputId": "114d23f1-7eec-4979-a09b-65babed857fa"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SK Parameters: 12.9441, -0.8589, -2.7129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# inferece with train data\n",
        "y_train_pred = sk_logis_regr.predict(X_train)\n",
        "print('SK train accuracy: %.4f' %\n",
        "      accuracy_score(y_train, y_train_pred) )\n",
        "\n",
        "# inferece with test data\n",
        "y_test_pred = sk_logis_regr.predict(X_test)\n",
        "print('SK test accuracy: %.4f' %\n",
        "      accuracy_score(y_test, y_test_pred) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlLUz6FS51g-",
        "outputId": "3a3660cc-04af-4b4c-eb3b-789ce20a93d3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SK train accuracy: 0.8714\n",
            "SK test accuracy: 0.9149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>[Lab #2-4]</font> Logisitic regression with PyTorch (20 points)\n"
      ],
      "metadata": {
        "id": "Ud6F-YyO1ymU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import `PyTorch` packages"
      ],
      "metadata": {
        "id": "AIv8_PMg_u1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "juou7sgD1mrl"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert data into `Tensor`, the inherence data type for `Pytorch`."
      ],
      "metadata": {
        "id": "5PoDfjiP_0ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.FloatTensor(y_train)\n",
        "\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.FloatTensor(y_test)"
      ],
      "metadata": {
        "id": "vGiWZoK49b5U"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define LogisiticRegression with [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) and [`sigmoid`](https://pytorch.org/docs/stable/generated/torch.sigmoid.html?highlight=sigmoid#torch.sigmoid)."
      ],
      "metadata": {
        "id": "n2zaGmJCAKSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import sigmoid\n",
        "import torch.nn as nn\n",
        "\n",
        "class LogsiticRegression(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear =  nn.Linear(2, 1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "      signal = self.linear(x)\n",
        "      y_pred = sigmoid(signal)\n",
        "      return y_pred"
      ],
      "metadata": {
        "id": "v_ESKjIY6IYM"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set hyper-parameter\n",
        "NUM_EPOCH = 20000\n",
        "LEARNING_RATE = 0.1"
      ],
      "metadata": {
        "id": "y_3EJQdlCHsl"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct your learning precedure\n",
        "\n",
        "1.   Create model with your own model class `LogisticRegression`\n",
        "2.   Define error term with Binary Cross Entropy [[ref](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)]\n",
        "3.   Define optimizer with Stochastic Gradient Descent [[ref](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html?highlight=sgd#torch.optim.SGD)]\n",
        "\n"
      ],
      "metadata": {
        "id": "2bluWKDVJq_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# create model\n",
        "torch_logis_regr = LogsiticRegression()\n",
        "\n",
        "# define error term\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "# define optimizer technique \n",
        "optimizer = torch.optim.SGD(torch_logis_regr.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "OjnFJoem2Es6"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCH):\n",
        "    # inference\n",
        "    prob = torch_logis_regr(X_train_tensor)\n",
        "\n",
        "    # compute loss\n",
        "    loss = criterion(prob.squeeze(), y_train_tensor)\n",
        "   \n",
        "    # remove previous gradient\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # compute gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # run optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    if not (epoch % 500):\n",
        "      print('epoch [%5d / %5d] %.4f' %\n",
        "            (epoch, NUM_EPOCH, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkdxBiwm6z08",
        "outputId": "024a7c59-287a-4a35-f6bd-4d7e14cf9d42"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [    0 / 20000] 3.8789\n",
            "epoch [  500 / 20000] 1.4894\n",
            "epoch [ 1000 / 20000] 1.5584\n",
            "epoch [ 1500 / 20000] 1.0936\n",
            "epoch [ 2000 / 20000] 0.2952\n",
            "epoch [ 2500 / 20000] 0.2897\n",
            "epoch [ 3000 / 20000] 0.2873\n",
            "epoch [ 3500 / 20000] 0.2851\n",
            "epoch [ 4000 / 20000] 0.2829\n",
            "epoch [ 4500 / 20000] 0.2808\n",
            "epoch [ 5000 / 20000] 0.2787\n",
            "epoch [ 5500 / 20000] 0.2768\n",
            "epoch [ 6000 / 20000] 0.2749\n",
            "epoch [ 6500 / 20000] 0.2731\n",
            "epoch [ 7000 / 20000] 0.2713\n",
            "epoch [ 7500 / 20000] 0.2696\n",
            "epoch [ 8000 / 20000] 0.2680\n",
            "epoch [ 8500 / 20000] 0.2664\n",
            "epoch [ 9000 / 20000] 0.2649\n",
            "epoch [ 9500 / 20000] 0.2635\n",
            "epoch [10000 / 20000] 0.2621\n",
            "epoch [10500 / 20000] 0.2607\n",
            "epoch [11000 / 20000] 0.2594\n",
            "epoch [11500 / 20000] 0.2581\n",
            "epoch [12000 / 20000] 0.2569\n",
            "epoch [12500 / 20000] 0.2557\n",
            "epoch [13000 / 20000] 0.2546\n",
            "epoch [13500 / 20000] 0.2535\n",
            "epoch [14000 / 20000] 0.2524\n",
            "epoch [14500 / 20000] 0.2514\n",
            "epoch [15000 / 20000] 0.2504\n",
            "epoch [15500 / 20000] 0.2495\n",
            "epoch [16000 / 20000] 0.2486\n",
            "epoch [16500 / 20000] 0.2477\n",
            "epoch [17000 / 20000] 0.2469\n",
            "epoch [17500 / 20000] 0.2460\n",
            "epoch [18000 / 20000] 0.2452\n",
            "epoch [18500 / 20000] 0.2445\n",
            "epoch [19000 / 20000] 0.2438\n",
            "epoch [19500 / 20000] 0.2431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inferece with train data\n",
        "y_train_prob = torch_logis_regr(X_train_tensor)\n",
        "y_train_pred = y_train_prob > 0.5\n",
        "print('Troch train accuracy: %.4f' %\n",
        "      accuracy_score(y_train, y_train_pred) )\n",
        "\n",
        "# inferece with test data\n",
        "y_test_prob = torch_logis_regr(X_test_tensor)\n",
        "y_test_pred = y_test_prob > 0.5\n",
        "print('Torch train accuracy: %.4f' %\n",
        "      accuracy_score(y_test, y_test_pred) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYsPsh8d8TA1",
        "outputId": "c09ea00f-baed-4051-ec23-ff71ddfd66e6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Troch train accuracy: 0.9029\n",
            "Torch train accuracy: 0.9255\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}